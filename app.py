"""
æ™ºèƒ½è§†è§‰åˆ†æåŠ©æ‰‹ - Flaskä¸»åº”ç”¨
"""
from flask import Flask, render_template, request, jsonify
from flask_socketio import SocketIO, emit
import cv2
import base64
import time
import json
from datetime import datetime

# å¯¼å…¥eventletä½†ä¸monkey_patchï¼ˆé¿å…é€’å½’é”™è¯¯ï¼‰
import eventlet

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from config import Config
from models.yolo_detector import YOLODetector
from models.qwen_client import QwenVLClient
from utils.video_processor import VideoProcessor
from utils.image_utils import resize_image, add_timestamp, image_to_base64

# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__)
app.config.from_object(Config)
# ç§»é™¤async_modeå‚æ•°ï¼Œè®©Flask-SocketIOè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å¼
socketio = SocketIO(app, cors_allowed_origins="*")

# å…¨å±€å˜é‡
video_processor = None
yolo_detector = None
qwen_client = None
is_processing = False
current_frame = None
detection_results = None

def initialize_components():
    """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
    global video_processor, yolo_detector, qwen_client
    
    print("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
    
    # åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨
    video_processor = VideoProcessor()
    
    # åˆå§‹åŒ–YOLOæ£€æµ‹å™¨
    yolo_detector = YOLODetector()
    
    # åˆå§‹åŒ–Qwenå®¢æˆ·ç«¯
    qwen_client = QwenVLClient()
    
    print("ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ!")

def video_stream_greenthread():
    """è§†é¢‘æµå¤„ç†greenthread - ä½¿ç”¨eventlet"""
    global is_processing, current_frame, detection_results
    
    print("ğŸ¥ è§†é¢‘æµgreenthreadå·²å¯åŠ¨ï¼ˆeventletæ¨¡å¼ï¼‰")
    frame_count = 0
    last_log_time = time.time()
    
    while True:
        try:
            # æ¯5ç§’æ‰“å°ä¸€æ¬¡çŠ¶æ€
            if time.time() - last_log_time > 5:
                print(f"ğŸ“Š çŠ¶æ€: æ‘„åƒå¤´å¯ç”¨={video_processor.is_camera_available() if video_processor else False}, å¸§æ•°={frame_count}")
                last_log_time = time.time()
            
            if video_processor and video_processor.is_camera_available():
                frame = video_processor.get_latest_frame()
                
                if frame is not None:
                    current_frame = frame.copy()
                    frame_count += 1
                    
                    # æ‰§è¡Œç›®æ ‡æ£€æµ‹
                    if yolo_detector and yolo_detector.is_model_ready():
                        detection_results = yolo_detector.detect_objects(frame)
                        annotated_frame = detection_results.get('annotated_frame', frame)
                    else:
                        annotated_frame = frame
                        detection_results = {"objects": [], "object_count": 0}
                    
                    # æ·»åŠ æ—¶é—´æˆ³
                    timestamped_frame = add_timestamp(annotated_frame)
                    
                    # è°ƒæ•´å›¾åƒå¤§å°ï¼ˆä½¿ç”¨é…ç½®çš„æœ€å¤§å°ºå¯¸ï¼‰
                    display_frame = resize_image(
                        timestamped_frame, 
                        max_width=Config.MAX_FRAME_WIDTH, 
                        max_height=Config.MAX_FRAME_HEIGHT
                    )
                    
                    # è½¬æ¢ä¸ºbase64å¹¶å‘é€ï¼ˆä½¿ç”¨é…ç½®çš„è´¨é‡ï¼‰
                    frame_base64 = image_to_base64(display_frame, quality=Config.STREAM_QUALITY)
                    if frame_base64:
                        try:
                            # ä½¿ç”¨eventletçš„æ–¹å¼å‘é€
                            with app.app_context():
                                socketio.emit('video_frame', {
                                    'frame': frame_base64,
                                    'detection_info': {
                                        'object_count': detection_results.get('object_count', 0),
                                        'objects': detection_results.get('objects', [])
                                    },
                                    'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                                }, namespace='/')
                            
                            # æ¯30å¸§æ‰“å°ä¸€æ¬¡çŠ¶æ€
                            if frame_count % 30 == 0:
                                print(f"ğŸ“¹ å·²å‘é€ {frame_count} å¸§, å¸§å¤§å°: {len(frame_base64)} å­—èŠ‚")
                        except Exception as e:
                            print(f"âŒ WebSocketå‘é€å¤±è´¥: {e}")
                    else:
                        if frame_count % 30 == 0:
                            print(f"âŒ å¸§è½¬æ¢å¤±è´¥")
            else:
                # æ‘„åƒå¤´æœªå¯åŠ¨æ—¶ç­‰å¾…
                eventlet.sleep(0.5)
            
            eventlet.sleep(1.0 / Config.STREAM_FPS)  # ä½¿ç”¨é…ç½®çš„æµå¸§ç‡
            
        except Exception as e:
            print(f"âŒ è§†é¢‘æµå¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            eventlet.sleep(1)

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/api/camera/start', methods=['POST'])
def start_camera():
    """å¯åŠ¨æ‘„åƒå¤´"""
    global video_greenthread
    try:
        if video_processor.start_capture():
            # å¯åŠ¨è§†é¢‘æµgreenthreadï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰
            if video_greenthread is None:
                video_greenthread = eventlet.spawn(video_stream_greenthread)
                print("âœ… è§†é¢‘æµgreenthreadå·²å¯åŠ¨")
            return jsonify({"success": True, "message": "æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ"})
        else:
            return jsonify({"success": False, "message": "æ‘„åƒå¤´å¯åŠ¨å¤±è´¥"})
    except Exception as e:
        return jsonify({"success": False, "message": f"å¯åŠ¨æ‘„åƒå¤´æ—¶å‡ºé”™: {str(e)}"})

@app.route('/api/camera/stop', methods=['POST'])
def stop_camera():
    """åœæ­¢æ‘„åƒå¤´"""
    try:
        video_processor.stop_capture()
        return jsonify({"success": True, "message": "æ‘„åƒå¤´å·²åœæ­¢"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åœæ­¢æ‘„åƒå¤´æ—¶å‡ºé”™: {str(e)}"})

@app.route('/api/camera/info', methods=['GET'])
def camera_info():
    """è·å–æ‘„åƒå¤´ä¿¡æ¯"""
    try:
        info = video_processor.get_camera_info()
        return jsonify({"success": True, "data": info})
    except Exception as e:
        return jsonify({"success": False, "message": f"è·å–æ‘„åƒå¤´ä¿¡æ¯å¤±è´¥: {str(e)}"})

@app.route('/api/detection/summary', methods=['GET'])
def detection_summary():
    """è·å–æ£€æµ‹æ‘˜è¦"""
    try:
        if detection_results and detection_results.get('objects'):
            summary = yolo_detector.get_detection_summary(detection_results['objects'])
            return jsonify({
                "success": True, 
                "summary": summary,
                "object_count": detection_results.get('object_count', 0),
                "objects": detection_results.get('objects', [])
            })
        else:
            return jsonify({
                "success": True, 
                "summary": "æœªæ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“",
                "object_count": 0,
                "objects": []
            })
    except Exception as e:
        return jsonify({"success": False, "message": f"è·å–æ£€æµ‹æ‘˜è¦å¤±è´¥: {str(e)}"})

@socketio.on('connect')
def handle_connect():
    """å®¢æˆ·ç«¯è¿æ¥"""
    print('å®¢æˆ·ç«¯å·²è¿æ¥')
    emit('status', {'message': 'è¿æ¥æˆåŠŸ'})

@socketio.on('disconnect')
def handle_disconnect():
    """å®¢æˆ·ç«¯æ–­å¼€è¿æ¥"""
    print('å®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥')

@socketio.on('ask_question')
def handle_question(data):
    """å¤„ç†ç”¨æˆ·é—®é¢˜"""
    try:
        print(f"ğŸ“¥ æ”¶åˆ°é—®é¢˜è¯·æ±‚: {data}")
        question = data.get('question', '')
        
        if not question:
            print("âŒ é—®é¢˜ä¸ºç©º")
            emit('ai_response', {'error': 'é—®é¢˜ä¸èƒ½ä¸ºç©º'})
            return
        
        if current_frame is None:
            print("âŒ å½“å‰æ²¡æœ‰è§†é¢‘å¸§")
            emit('ai_response', {'error': 'å½“å‰æ²¡æœ‰å¯ç”¨çš„è§†é¢‘å¸§'})
            return
        
        print(f"ğŸ¤– å¼€å§‹è°ƒç”¨AIæ¨¡å‹åˆ†æé—®é¢˜: {question}")
        
        # ä½¿ç”¨Qwenåˆ†æå½“å‰å¸§
        response = qwen_client.answer_question(
            current_frame, 
            question, 
            detection_results
        )
        
        print(f"âœ… AIå›ç­”ç”ŸæˆæˆåŠŸ: {response[:100]}...")
        
        response_data = {
            'question': question,
            'answer': response,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        print(f"ğŸ“¤ å‘é€AIå›ç­”åˆ°å‰ç«¯")
        emit('ai_response', response_data)
        
    except Exception as e:
        print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        emit('ai_response', {'error': f'å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}'})

@socketio.on('analyze_scene')
def handle_scene_analysis():
    """åœºæ™¯åˆ†æ"""
    try:
        print("ğŸ” å¼€å§‹åœºæ™¯åˆ†æ...")
        
        if current_frame is None:
            print("âŒ å½“å‰æ²¡æœ‰è§†é¢‘å¸§")
            emit('scene_analysis', {'error': 'å½“å‰æ²¡æœ‰å¯ç”¨çš„è§†é¢‘å¸§'})
            return
        
        print("ğŸ¤– è°ƒç”¨AIè¿›è¡Œåœºæ™¯æè¿°...")
        # è·å–åœºæ™¯æè¿°
        description = qwen_client.get_scene_description(current_frame, detection_results)
        
        print("ğŸ›¡ï¸ è¿›è¡Œå®‰å…¨æ£€æŸ¥...")
        # å®‰å…¨æ£€æŸ¥
        safety_check = qwen_client.check_safety(current_frame, detection_results)
        
        print("âœ… åœºæ™¯åˆ†æå®Œæˆ")
        
        emit('scene_analysis', {
            'description': description,
            'safety': safety_check,
            'detection_summary': yolo_detector.get_detection_summary(
                detection_results.get('objects', []) if detection_results else []
            ),
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })
        
    except Exception as e:
        print(f"âŒ åœºæ™¯åˆ†ææ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        emit('scene_analysis', {'error': f'åœºæ™¯åˆ†ææ—¶å‡ºé”™: {str(e)}'})

@socketio.on('capture_image')
def handle_capture():
    """æ•è·å½“å‰å›¾åƒ"""
    try:
        if current_frame is None:
            emit('image_captured', {'error': 'å½“å‰æ²¡æœ‰å¯ç”¨çš„è§†é¢‘å¸§'})
            return
        
        # ä¿å­˜å›¾åƒ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"capture_{timestamp}.jpg"
        
        # æ·»åŠ æ—¶é—´æˆ³åˆ°å›¾åƒ
        timestamped_frame = add_timestamp(current_frame)
        cv2.imwrite(f"static/captures/{filename}", timestamped_frame)
        
        # è½¬æ¢ä¸ºbase64ç”¨äºæ˜¾ç¤º
        image_base64 = image_to_base64(timestamped_frame)
        
        emit('image_captured', {
            'filename': filename,
            'image': image_base64,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })
        
    except Exception as e:
        print(f"æ•è·å›¾åƒæ—¶å‡ºé”™: {e}")
        emit('image_captured', {'error': f'æ•è·å›¾åƒæ—¶å‡ºé”™: {str(e)}'})

# å…¨å±€è§†é¢‘æµgreenthread
video_greenthread = None

if __name__ == '__main__':
    # åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
    initialize_components()
    
    # ä¸åœ¨å¯åŠ¨æ—¶å¯åŠ¨è§†é¢‘æµçº¿ç¨‹ï¼Œç­‰å¾…æ‘„åƒå¤´å¯åŠ¨åå†å¯åŠ¨
    # è¿™æ ·å¯ä»¥é¿å…WebSocketè¿æ¥é—®é¢˜
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    import os
    os.makedirs('static/captures', exist_ok=True)
    
    print(f"æ™ºèƒ½è§†è§‰åˆ†æåŠ©æ‰‹å¯åŠ¨ä¸­...")
    print(f"è®¿é—®åœ°å€: http://{Config.HOST}:{Config.PORT}")
    print("ğŸ’¡ æç¤º: ç‚¹å‡»'å¯åŠ¨'æŒ‰é’®åè§†é¢‘æµå°†å¼€å§‹ä¼ è¾“")
    
    # å¯åŠ¨Flaskåº”ç”¨
    print("ğŸš€ å¯åŠ¨SocketIOæœåŠ¡å™¨...")
    socketio.run(
        app, 
        host=Config.HOST, 
        port=Config.PORT, 
        debug=False,
        allow_unsafe_werkzeug=True
    )